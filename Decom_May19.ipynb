{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNM5cXj5a8S6DSc9N761naO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Denoise/blob/main/Decom_May19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# Cell 1: Environment Setup\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision # Explicitly import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import gdown\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install required packages\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install scikit-image\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Create directory for dataset\n",
        "os.makedirs('/content/dataset', exist_ok=True)\n",
        "\n",
        "# Output: Table of installed packages\n",
        "packages = ['torch', 'torchvision', 'scikit-image']\n",
        "versions = [torch.__version__, torchvision.__version__, 'scikit-image']\n",
        "pd.DataFrame({'Package': packages, 'Version': versions}).style.set_caption(\"Installed Packages\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "id": "j5PTe29PctHs",
        "outputId": "81371e88-ca72-4811-cacf-fa72944ea0bf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.15.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (11.2.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.5.10)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7e7712d25690>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_ae397\" class=\"dataframe\">\n",
              "  <caption>Installed Packages</caption>\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_ae397_level0_col0\" class=\"col_heading level0 col0\" >Package</th>\n",
              "      <th id=\"T_ae397_level0_col1\" class=\"col_heading level0 col1\" >Version</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_ae397_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_ae397_row0_col0\" class=\"data row0 col0\" >torch</td>\n",
              "      <td id=\"T_ae397_row0_col1\" class=\"data row0 col1\" >2.6.0+cu124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ae397_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_ae397_row1_col0\" class=\"data row1 col0\" >torchvision</td>\n",
              "      <td id=\"T_ae397_row1_col1\" class=\"data row1 col1\" >0.21.0+cu124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ae397_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_ae397_row2_col0\" class=\"data row2 col0\" >scikit-image</td>\n",
              "      <td id=\"T_ae397_row2_col1\" class=\"data row2 col1\" >scikit-image</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "PBVsenz1bYmm",
        "outputId": "4434f832-88d4-43ff-d8af-66a477ba09aa"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name '_Loss' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-1988c24ce412>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Cell 2: Model Definition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0msum_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_squared_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name '_Loss' is not defined"
          ]
        }
      ],
      "source": [
        "# Cell 2: Model Definition\n",
        "class sum_squared_error(_Loss):\n",
        "    def __init__(self, reduction='sum'):\n",
        "        super(sum_squared_error, self).__init__(reduction=reduction)\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        return torch.nn.functional.mse_loss(input, target, reduction='sum').div_(2)\n",
        "\n",
        "class UNet_Atten_3(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3):\n",
        "        super(UNet_Atten_3, self).__init__()\n",
        "        # Encoder and Decoder blocks as provided\n",
        "        self._block1_dw = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 48, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(48, 48, 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2))\n",
        "        self._block2_dw = nn.Sequential(\n",
        "            nn.Conv2d(48, 48, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2))\n",
        "        self._block3_dw = nn.Sequential(\n",
        "            nn.Conv2d(48, 48, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(48, 48, 3, stride=2, padding=1, output_padding=1))\n",
        "        self._block4_dw = nn.Sequential(\n",
        "            nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(96, 96, 3, stride=2, padding=1, output_padding=1))\n",
        "        self._block5_dw = nn.Sequential(\n",
        "            nn.Conv2d(144, 96, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(96, 96, 3, stride=2, padding=1, output_padding=1))\n",
        "        self._block6_dw = nn.Sequential(\n",
        "            nn.Conv2d(96 + in_channels, 64, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 32, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, out_channels, 3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(0.1))\n",
        "        self._block1_dw2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 48, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(48, 48, 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2))\n",
        "        self._block2_dw2 = nn.Sequential(\n",
        "            nn.Conv2d(48, 48, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2))\n",
        "        self._block3_dw2 = nn.Sequential(\n",
        "            nn.Conv2d(48, 48, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(48, 48, 3, stride=2, padding=1, output_padding=1))\n",
        "        self._block4_dw2 = nn.Sequential(\n",
        "            nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(96, 96, 3, stride=2, padding=1, output_padding=1))\n",
        "        self._block5_dw2 = nn.Sequential(\n",
        "            nn.Conv2d(144, 96, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(96, 96, 3, stride=2, padding=1, output_padding=1))\n",
        "        self._block6_dw2 = nn.Sequential(\n",
        "            nn.Conv2d(96 + in_channels, 64, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 32, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, out_channels, 3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(0.1))\n",
        "        self._block1_dn = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 48, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(48, 48, 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2))\n",
        "        self._block2_dn = nn.Sequential(\n",
        "            nn.Conv2d(48, 48, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2))\n",
        "        self._block3_dn = nn.Sequential(\n",
        "            nn.Conv2d(48, 48, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(48, 48, 3, stride=2, padding=1, output_padding=1))\n",
        "        self._block4_dn = nn.Sequential(\n",
        "            nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(96, 96, 3, stride=2, padding=1, output_padding=1))\n",
        "        self._block5_dn = nn.Sequential(\n",
        "            nn.Conv2d(144, 96, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(96, 96, 3, stride=2, padding=1, output_padding=1))\n",
        "        self._block6_dn = nn.Sequential(\n",
        "            nn.Conv2d(96 + in_channels, 64, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 32, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, out_channels, 3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(0.1))\n",
        "        self._block1_wm = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 48, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(48, 48, 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2))\n",
        "        self._block2_wm = nn.Sequential(\n",
        "            nn.Conv2d(48, 48, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2))\n",
        "        self._block3_wm = nn.Sequential(\n",
        "            nn.Conv2d(48, 48, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(48, 48, 3, stride=2, padding=1, output_padding=1))\n",
        "        self._block4_wm = nn.Sequential(\n",
        "            nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(96, 96, 3, stride=2, padding=1, output_padding=1))\n",
        "        self._block5_wm = nn.Sequential(\n",
        "            nn.Conv2d(144, 96, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(96, 96, 3, stride=2, padding=1, output_padding=1))\n",
        "        self._block6_wm = nn.Sequential(\n",
        "            nn.Conv2d(96 + in_channels, 64, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 32, 3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, out_channels, 3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(0.1))\n",
        "        self.avg_dn = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.attn_dn = nn.Sequential(\n",
        "            nn.Conv2d(144, 6, kernel_size=1, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(6, 144, kernel_size=1, stride=1),\n",
        "            nn.Sigmoid())\n",
        "        self.avg_wm = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.attn_wm = nn.Sequential(\n",
        "            nn.Conv2d(144, 6, kernel_size=1, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(6, 144, kernel_size=1, stride=1),\n",
        "            nn.Sigmoid())\n",
        "        self.out = nn.Sequential(\n",
        "            nn.Conv2d(out_channels * 2, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "            nn.LeakyReLU(0.1))\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight.data)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        pool1_dn = self._block1_dn(x)\n",
        "        pool2_dn = self._block2_dn(pool1_dn)\n",
        "        pool3_dn = self._block2_dn(pool2_dn)\n",
        "        pool4_dn = self._block2_dn(pool3_dn)\n",
        "        pool5_dn = self._block2_dn(pool4_dn)\n",
        "        upsample5_dn = self._block3_dn(pool5_dn)\n",
        "        concat5_dn = torch.cat((upsample5_dn, pool4_dn), dim=1)\n",
        "        upsample4_dn = self._block4_dn(concat5_dn)\n",
        "        concat4_dn = torch.cat((upsample4_dn, pool3_dn), dim=1)\n",
        "        upsample3_dn = self._block5_dn(concat4_dn)\n",
        "        concat3_dn = torch.cat((upsample3_dn, pool2_dn), dim=1)\n",
        "        upsample2_dn = self._block5_dn(concat3_dn)\n",
        "        concat2_dn = torch.cat((upsample2_dn, pool1_dn), dim=1)\n",
        "        upsample1_dn = self._block5_dn(concat2_dn)\n",
        "        concat1_dn = torch.cat((upsample1_dn, x), dim=1)\n",
        "        out_denoise = self._block6_dn(concat1_dn)\n",
        "        pool1_wm = self._block1_wm(out_denoise)\n",
        "        pool2_wm = self._block2_wm(pool1_wm)\n",
        "        pool3_wm = self._block2_wm(pool2_wm)\n",
        "        pool4_wm = self._block2_wm(pool3_wm)\n",
        "        pool5_wm = self._block2_wm(pool4_wm)\n",
        "        upsample5_wm = self._block3_wm(pool5_wm)\n",
        "        concat5_wm = torch.cat((upsample5_wm, pool4_wm), dim=1)\n",
        "        upsample4_wm = self._block4_wm(concat5_wm)\n",
        "        concat4_wm = torch.cat((upsample4_wm, pool3_wm), dim=1)\n",
        "        upsample3_wm = self._block5_wm(concat4_wm)\n",
        "        concat3_wm = torch.cat((upsample3_wm, pool2_wm), dim=1)\n",
        "        upsample2_wm = self._block5_wm(concat3_wm)\n",
        "        concat2_wm = torch.cat((upsample2_wm, pool1_wm), dim=1)\n",
        "        upsample1_wm = self._block5_wm(concat2_wm)\n",
        "        concat1_wm = torch.cat((upsample1_wm, x), dim=1)\n",
        "        out_wm = self._block6_wm(concat1_wm)\n",
        "        pool1_dw = self._block1_dw(x)\n",
        "        pool2_dw = self._block2_dw(pool1_dw)\n",
        "        pool3_dw = self._block2_dw(pool2_dw)\n",
        "        pool4_dw = self._block2_dw(pool3_dw)\n",
        "        pool5_dw = self._block2_dw(pool4_dw)\n",
        "        upsample5_dw = self._block3_dw(pool5_dw)\n",
        "        concat5_dw = torch.cat((upsample5_dw, pool4_dw), dim=1)\n",
        "        upsample4_dw = self._block4_dw(concat5_dw)\n",
        "        concat4_dw = torch.cat((upsample4_dw, pool3_dw), dim=1)\n",
        "        upsample3_dw = self._block5_dw(concat4_dw)\n",
        "        concat3_dw = torch.cat((upsample3_dw, pool2_dw), dim=1)\n",
        "        upsample2_dw = self._block5_dw(concat3_dw)\n",
        "        concat2_dw = torch.cat((upsample2_dw, pool1_dw), dim=1)\n",
        "        mid_dn = self.avg_dn(concat2_dn)\n",
        "        Scale_dn = self.attn_dn(mid_dn)\n",
        "        concat2_dw = concat2_dw * Scale_dn\n",
        "        upsample1_dw = self._block5_dw(concat2_dw)\n",
        "        concat1_dw = torch.cat((upsample1_dw, x), dim=1)\n",
        "        main_out_mid = self._block6_dw(concat1_dw)\n",
        "        pool1_dw2 = self._block1_dw2(main_out_mid)\n",
        "        pool2_dw2 = self._block2_dw2(pool1_dw2)\n",
        "        pool3_dw2 = self._block2_dw2(pool2_dw2)\n",
        "        pool4_dw2 = self._block2_dw(pool3_dw2)\n",
        "        pool5_dw2 = self._block2_dw(pool4_dw2)\n",
        "        upsample5_dw2 = self._block3_dw(pool5_dw2)\n",
        "        concat5_dw2 = torch.cat((upsample5_dw2, pool4_dw2), dim=1)\n",
        "        upsample4_dw2 = self._block4_dw(concat5_dw2)\n",
        "        concat4_dw2 = torch.cat((upsample4_dw2, pool3_dw2), dim=1)\n",
        "        upsample3_dw2 = self._block5_dw(concat4_dw2)\n",
        "        concat3_dw2 = torch.cat((upsample3_dw2, pool2_dw2), dim=1)\n",
        "        upsample2_dw2 = self._block5_dw(concat3_dw2)\n",
        "        concat2_dw2 = torch.cat((upsample2_dw2, pool1_dw2), dim=1)\n",
        "        mid_wm = self.avg_wm(concat2_wm)\n",
        "        Scale_wm = self.attn_wm(mid_wm)\n",
        "        concat2_dw2 = concat2_dw2 * Scale_wm\n",
        "        upsample1_dw2 = self._block5_dw2(concat2_dw2)\n",
        "        concat1_dw2 = torch.cat((upsample1_dw2, x), dim=1)\n",
        "        main_out_final = self._block6_dw2(concat1_dw2)\n",
        "        return main_out_final, out_denoise, out_wm\n",
        "\n",
        "# Initialize model\n",
        "model = UNet_Atten_3().to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total parameters: {total_params}\")\n",
        "\n",
        "# Output: Table of model summary\n",
        "data = {'Component': ['Total Parameters'], 'Count': [total_params]}\n",
        "pd.DataFrame(data).style.set_caption(\"Model Summary\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OojBrQyicbz6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
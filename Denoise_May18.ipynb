{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOCIfK6vDpfj3/mQUeb048",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Denoise/blob/main/Denoise_May18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Set Up Environment\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psFQJI6yCapl",
        "outputId": "6c914523-ddda-40aa-ec78-581d861e3069"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install torchvision opencv-python h5py kagglehub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXPUPmg4Cc4G",
        "outputId": "e6d5969c-d2b5-4886-8d3b-d59ec4cd48e7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (3.13.0)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.6.0+cu124)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import h5py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as udata\n",
        "import cv2\n",
        "import glob\n",
        "from torch.nn.modules.loss import _Loss\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
        "import argparse\n",
        "import time\n",
        "import math\n",
        "import string\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "te6JlhzHCfwF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Download Pascal VOC 2012 dataset\n",
        "print(\"Downloading Pascal VOC 2012 dataset...\")\n",
        "path = kagglehub.dataset_download(\"gopalbhattrai/pascal-voc-2012-dataset\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Create directories\n",
        "base_dir = '/content/drive/MyDrive/SSNet'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "os.makedirs(f'{base_dir}/data', exist_ok=True)\n",
        "os.makedirs(f'{base_dir}/data/Kodak24', exist_ok=True) # For testing\n",
        "os.makedirs(f'{base_dir}/logos', exist_ok=True)\n",
        "os.makedirs(f'{base_dir}/saved_models', exist_ok=True)\n",
        "os.makedirs(f'{base_dir}/ckpts', exist_ok=True)\n",
        "os.makedirs(f'{base_dir}/output', exist_ok=True)\n",
        "\n",
        "# Step 2: Define Utility Functions (utils.py equivalent)\n",
        "def seed_torch(seed=1029):\n",
        " random.seed(seed)\n",
        " os.environ['PYTHONHASHSEED'] = str(seed)\n",
        " np.random.seed(seed)\n",
        " torch.manual_seed(seed)\n",
        " torch.cuda.manual_seed(seed)\n",
        " torch.cuda.manual_seed_all(seed)\n",
        " torch.backends.cudnn.benchmark = False\n",
        " torch.backends.cudnn.deterministic = True\n",
        "\n",
        "def weights_init_kaiming(m):\n",
        " classname = m.__class__.__name__\n",
        " if classname.find('Conv') != -1:\n",
        " nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
        " elif classname.find('Linear') != -1:\n",
        " nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
        " elif classname.find('BatchNorm') != -1:\n",
        " m.weight.data.normal_(mean=0, std=math.sqrt(2./9./64.)).clamp_(-0.025, 0.025)\n",
        " nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "def batch_PSNR(img, imclean, data_range):\n",
        " Img = img.data.cpu().numpy().astype(np.float32)\n",
        " Iclean = imclean.data.cpu().numpy().astype(np.float32)\n",
        " PSNR = 0\n",
        " for i in range(Img.shape[0]):\n",
        " PSNR += peak_signal_noise_ratio(Iclean[i, :, :, :], Img[i, :, :, :], data_range=data_range)\n",
        " return PSNR / Img.shape[0]\n",
        "\n",
        "def data_augmentation(image, mode):\n",
        " out = np.transpose(image, (1, 2, 0))\n",
        " if mode == 0:\n",
        " out = out\n",
        " elif mode == 1:\n",
        " out = np.flipud(out)\n",
        " elif mode == 2:\n",
        " out = np.rot90(out)\n",
        " elif mode == 3:\n",
        " out = np.rot90(out)\n",
        " out = np.flipud(out)\n",
        " elif mode == 4:\n",
        " out = np.rot90(out, k=2)\n",
        " elif mode == 5:\n",
        " out = np.rot90(out, k=2)\n",
        " out = np.flipud(out)\n",
        " elif mode == 6:\n",
        " out = np.rot90(out, k=3)\n",
        " elif mode == 7:\n",
        " out = np.rot90(out, k=3)\n",
        " out = np.flipud(out)\n",
        " return np.transpose(out, (2, 0, 1))\n",
        "\n",
        "def add_text_noise(noise, occupancy=50):\n",
        " font = cv2.FONT_HERSHEY_SIMPLEX\n",
        " h, w, _ = noise.shape\n",
        " img_for_cnt = np.zeros((h, w), np.uint8)\n",
        " occupancy = np.random.uniform(0, occupancy)\n",
        " while True:\n",
        " n = random.randint(5, 10)\n",
        " random_str = ''.join([random.choice(string.ascii_letters + string.digits) for i in range(n)])\n",
        " font_scale = np.random.uniform(0.5, 1)\n",
        " thickness = random.randint(1, 3)\n",
        " (fw, fh), baseline = cv2.getTextSize(random_str, font, font_scale, thickness)\n",
        " x = random.randint(0, max(0, w - 1 - fw))\n",
        " y = random.randint(fh, h - 1 - baseline)\n",
        " color = (random.random(), random.random(), random.random())\n",
        " cv2.putText(noise, random_str, (x, y), font, font_scale, color, thickness)\n",
        " cv2.putText(img_for_cnt, random_str, (x, y), font, font_scale, 255, thickness)\n",
        " if (img_for_cnt > 0).sum() > h * w * occupancy / 100:\n",
        " break\n",
        " return noise\n",
        "\n",
        "def add_watermark_noise(img_train, scale_lists=None, idx_lists=None, is_test=False, threshold=50):\n",
        " watermarks = []\n",
        " logo_dir = f'{base_dir}/logos'\n",
        " for ii in range(12):\n",
        " logo_path = os.path.join(logo_dir, f'{ii+1:02d}.png')\n",
        " if os.path.exists(logo_path):\n",
        " watermarks.append(Image.open(logo_path))\n",
        " else:\n",
        " print(f\"Warning: Logo {logo_path} not found\")\n",
        " watermarks.append(Image.new('RGBA', (100, 100)))\n",
        "\n",
        " img_train = img_train.numpy()\n",
        " imgn_train = img_train.copy()\n",
        " _, _, img_h, img_w = img_train.shape\n",
        " img_train = np.transpose(img_train, (0, 2, 3, 1))\n",
        " imgn_train = np.transpose(imgn_train, (0, 2, 3, 1))\n",
        " ans_scale_lists = scale_lists if scale_lists else []\n",
        " ans_idx_lists = idx_lists if idx_lists else []\n",
        "\n",
        " for i in range(len(img_train)):\n",
        " tmp = Image.fromarray((img_train[i] * 255).astype(np.uint8))\n",
        " img_for_cnt = Image.fromarray(np.zeros((img_h, img_w, 3), np.uint8))\n",
        "\n",
        " if scale_lists is None:\n",
        " scale_list = []\n",
        " idx = random.randint(0, len(watermarks)-1)\n",
        " ans_idx_lists.append(idx)\n",
        " watermark = watermarks[idx]\n",
        " w, h = watermark.size\n",
        " mark_size = np.array(watermark).size\n",
        " occupancy = threshold if is_test else np.random.uniform(0, 10)\n",
        " cnt, ratio = 0, img_w * img_h * 3 * occupancy / 100\n",
        " finish = False\n",
        " while True:\n",
        " if (ratio - cnt) < mark_size * 0.3:\n",
        " img_train[i] = np.array(tmp).astype(np.float64) / 255.\n",
        " break\n",
        " elif (ratio - cnt) < mark_size:\n",
        " scale = (ratio - cnt) * 1.0 / mark_size\n",
        " finish = True\n",
        " else:\n",
        " scale = np.random.uniform(0.5, 1)\n",
        " scale_list.append(scale)\n",
        "\n",
        " water = watermark.resize((int(w * scale), int(h * scale)))\n",
        " x = random.randint(0, img_w - int(w * scale))\n",
        " y = random.randint(0, img_h - int(h * scale))\n",
        " tmp.paste(water, (x, y), water)\n",
        " img_for_cnt.paste(water, (x, y), water)\n",
        " img_cnt = np.array(img_for_cnt)\n",
        " cnt = (img_cnt > 0).sum()\n",
        " if finish:\n",
        " img_train[i] = np.array(tmp).astype(np.float64) / 255.\n",
        " break\n",
        " ans_scale_lists.append(scale_list)\n",
        " else:\n",
        " scale_list = scale_lists[i]\n",
        " idx = idx_lists[i]\n",
        " watermark = watermarks[idx]\n",
        " w, h = watermark.size\n",
        " for ii in range(len(scale_list)):\n",
        " scale = scale_list[ii]\n",
        " water = watermark.resize((int(w * scale), int(h * scale)))\n",
        " x = random.randint(0, img_w - int(w * scale))\n",
        " y = random.randint(0, img_h - int(h * scale))\n",
        " tmp.paste(water, (x, y), water)\n",
        " img_train[i] = np.array(tmp).astype(np.float64) / 255.\n",
        "\n",
        " img_train = np.transpose(img_train, (0, 3, 1, 2))\n",
        " imgn_train = np.transpose(imgn_train, (0, 3, 1, 2))\n",
        " return img_train, img_train - imgn_train, ans_scale_lists, ans_idx_lists\n",
        "\n",
        "def add_watermark_noise_test(img, num_wm=1):\n",
        " watermarks = []\n",
        " logo_dir = f'{base_dir}/logos'\n",
        " for ii in range(12):\n",
        " logo_path = os.path.join(logo_dir, f'{ii+1:02d}.png')\n",
        " if os.path.exists(logo_path):\n",
        " watermarks.append(Image.open(logo_path))\n",
        " else:\n",
        " watermarks.append(Image.new('RGBA', (100, 100)))\n",
        "\n",
        " img = img.numpy()\n",
        " imgn = img.copy()\n",
        " _, _, img_h, img_w = img.shape\n",
        " img = np.transpose(img, (0, 2, 3, 1))\n",
        " imgn = np.transpose(imgn, (0, 2, 3, 1))\n",
        "\n",
        " for i in range(len(img)):\n",
        " tmp = Image.fromarray((img[i] * 255).astype(np.uint8))\n",
        " idx = random.randint(0, len(watermarks)-1)\n",
        " watermark = watermarks[idx]\n",
        " w, h = watermark.size\n",
        " for ii in range(num_wm):\n",
        " scale = np.random.uniform(0.5, 1)\n",
        " water = watermark.resize((int(w * scale), int(h * scale)))\n",
        " x = random.randint(0, img_w - int(w * scale))\n",
        " y = random.randint(0, img_h - int(h * scale))\n",
        " tmp.paste(water, (x, y), water)\n",
        " img[i] = np.array(tmp).astype(np.float64) / 255.\n",
        "\n",
        " img = np.transpose(img, (0, 3, 1, 2))\n",
        " imgn = np.transpose(imgn, (0, 3, 1, 2))\n",
        " return img, img - imgn\n",
        "\n",
        "def findLastCheckpoint(save_path):\n",
        " files = glob.glob(os.path.join(save_path, '*.pth'))\n",
        " last_epoch = -1\n",
        " for fi in files:\n",
        " epoch = int(os.path.basename(fi)[-7:-4])\n",
        " if last_epoch < epoch:\n",
        " last_epoch = epoch\n",
        " return last_epoch\n",
        "\n",
        "# Step 3: Define Data Preparation\n",
        "def normalize(data):\n",
        " return data / 255.\n",
        "\n",
        "def Im2Patch(img, win, stride=1):\n",
        " k = 0\n",
        " endc = img.shape[0]\n",
        " endw = img.shape[1]\n",
        " endh = img.shape[2]\n",
        " patch = img[:, 0:endw-win+0+1:stride, 0:endh-win+0+1:stride]\n",
        " TotalPatNum = patch.shape[1] * patch.shape[2]\n",
        " Y = np.zeros([endc, win*win, TotalPatNum], np.float32)\n",
        " for i in range(win):\n",
        " for j in range(win):\n",
        " patch = img[:, i:endw-win+i+1:stride, j:endh-win+j+1:stride]\n",
        " Y[:, k, :] = np.array(patch[:]).reshape(endc, TotalPatNum)\n",
        " k = k + 1\n",
        " return Y.reshape([endc, win, win, TotalPatNum])\n",
        "\n",
        "def prepare_data(data_path, voc_path, patch_size, stride, aug_times=1, mode='color'):\n",
        " print('Process training data')\n",
        " scales = [1, 0.9, 0.8, 0.7]\n",
        "\n",
        " # Get all JPEG images from VOC2012/JPEGImages\n",
        " files = glob.glob(os.path.join(voc_path, 'VOC2012/JPEGImages', '*.jpg'))\n",
        " files.sort()\n",
        "\n",
        " # Split into train (80%) and validation (20%)\n",
        " random.seed(42)\n",
        " random.shuffle(files)\n",
        " split_idx = int(0.8 * len(files))\n",
        " train_files = files[:split_idx]\n",
        " val_files = files[split_idx:]\n",
        "\n",
        " # Process training data\n",
        " h5f = h5py.File(os.path.join(data_path, 'train_color_right.h5'), 'w')\n",
        " train_num = 0\n",
        " for i in range(len(train_files)):\n",
        " img = cv2.imread(train_files[i])\n",
        " h, w, c = img.shape\n",
        " for k in range(len(scales)):\n",
        " if int(h * scales[k]) < 256 or int(w * scales[k]) < 256:\n",
        " continue\n",
        " Img = cv2.resize(img, (int(h * scales[k]), int(w * scales[k])), interpolation=cv2.INTER_CUBIC)\n",
        " Img = np.transpose(Img, (2, 0, 1))\n",
        " Img = np.float32(normalize(Img))\n",
        " patches = Im2Patch(Img, win=patch_size, stride=stride)\n",
        " for n in range(patches.shape[3]):\n",
        " data = patches[:, :, :, n].copy()\n",
        " h5f.create_dataset(str(train_num), data=data)\n",
        " train_num += 1\n",
        " for m in range(aug_times - 1):\n",
        " data_aug = data_augmentation(data, np.random.randint(1, 8))\n",
        " h5f.create_dataset(str(train_num) + \"_aug_%d\" % (m + 1), data=data_aug)\n",
        " train_num += 1\n",
        " h5f.close()\n",
        "\n",
        " # Process validation data\n",
        " print('\\nProcess validation data')\n",
        " h5f = h5py.File(os.path.join(data_path, 'val_color_right.h5'), 'w')\n",
        " val_num = 0\n",
        " for i in range(len(val_files)):\n",
        " img = cv2.imread(val_files[i])\n",
        " img = np.transpose(img, (2, 0, 1))\n",
        " img = np.float32(normalize(img))\n",
        " h5f.create_dataset(str(val_num), data=img)\n",
        " val_num += 1\n",
        " h5f.close()\n",
        " print(f'Training set, # samples {train_num}')\n",
        " print(f'Validation set, # samples {val_num}')\n",
        "\n",
        "# Step 4: Define Dataset\n",
        "class Dataset(udata.Dataset):\n",
        " def __init__(self, train=True):\n",
        " super(Dataset, self).__init__()\n",
        " self.train = train\n",
        " data_path = f'{base_dir}/data'\n",
        " h5f = h5py.File(os.path.join(data_path, 'train_color_right.h5'), 'r') if train else h5py.File(os.path.join(data_path, 'val_color_right.h5'), 'r')\n",
        " self.keys = list(h5f.keys())\n",
        " random.shuffle(self.keys)\n",
        " h5f.close()\n",
        "\n",
        " def __len__(self):\n",
        " return len(self.keys)\n",
        "\n",
        " def __getitem__(self, index):\n",
        " data_path = f'{base_dir}/data'\n",
        " h5f = h5py.File(os.path.join(data_path, 'train_color_right.h5'), 'r') if self.train else h5py.File(os.path.join(data_path, 'val_color_right.h5'), 'r')\n",
        " key = self.keys[index]\n",
        " data = np.array(h5f[key])\n",
        " h5f.close()\n",
        " return torch.Tensor(data)\n",
        "\n",
        "# Step 5: Define Models\n",
        "class sum_squared_error(_Loss):\n",
        " def __init__(self, size_average=None, reduce=None, reduction='sum'):\n",
        " super(sum_squared_error, self).__init__(size_average, reduce, reduction)\n",
        "\n",
        " def forward(self, input, target):\n",
        " return torch.nn.functional.mse_loss(input, target, size_average=None, reduce=None, reduction='sum').div_(2)\n",
        "\n",
        "class UNet_Atten_3(nn.Module):\n",
        " def __init__(self, in_channels=3, out_channels=3):\n",
        " super(UNet_Atten_3, self).__init__()\n",
        " self._block1_dw = nn.Sequential(\n",
        " nn.Conv2d(in_channels, 48, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.Conv2d(48, 48, 3, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.MaxPool2d(2))\n",
        " self._block2_dw = nn.Sequential(\n",
        " nn.Conv2d(48, 48, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.MaxPool2d(2))\n",
        " self._block3_dw = nn.Sequential(\n",
        " nn.Conv2d(48, 48, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.ConvTranspose2d(48, 48, 3, stride=2, padding=1, output_padding=1))\n",
        " self._block4_dw = nn.Sequential(\n",
        " nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.ConvTranspose2d(96, 96, 3, stride=2, padding=1, output_padding=1))\n",
        " self._block5_dw = nn.Sequential(\n",
        " nn.Conv2d(144, 96, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.ConvTranspose2d(96, 96, 3, stride=2, padding=1, output_padding=1))\n",
        " self._block6_dw = nn.Sequential(\n",
        " nn.Conv2d(96 + in_channels, 64, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.Conv2d(64, 32, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.Conv2d(32, out_channels, 3, stride=1, padding=1),\n",
        " nn.LeakyReLU(0.1))\n",
        " self._block1_dw2 = nn.Sequential(\n",
        " nn.Conv2d(in_channels, 48, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.Conv2d(48, 48, 3, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.MaxPool2d(2))\n",
        " self._block2_dw2 = nn.Sequential(\n",
        " nn.Conv2d(48, 48, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.MaxPool2d(2))\n",
        " self._block3_dw2 = nn.Sequential(\n",
        " nn.Conv2d(48, 48, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.ConvTranspose2d(48, 48, 3, stride=2, padding=1, output_padding=1))\n",
        " self._block4_dw2 = nn.Sequential(\n",
        " nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.ConvTranspose2d(96, 96, 3, stride=2, padding=1, output_padding=1))\n",
        " self._block5_dw2 = nn.Sequential(\n",
        " nn.Conv2d(144, 96, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.ConvTranspose2d(96, 96, 3, stride=2, padding=1, output_padding=1))\n",
        " self._block6_dw2 = nn.Sequential(\n",
        " nn.Conv2d(96 + in_channels, 64, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.Conv2d(64, 32, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.Conv2d(32, out_channels, 3, stride=1, padding=1),\n",
        " nn.LeakyReLU(0.1))\n",
        " self._block1_dn = nn.Sequential(\n",
        " nn.Conv2d(in_channels, 48, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.Conv2d(48, 48, 3, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.MaxPool2d(2))\n",
        " self._block2_dn = nn.Sequential(\n",
        " nn.Conv2d(48, 48, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.MaxPool2d(2))\n",
        " self._block3_dn = nn.Sequential(\n",
        " nn.Conv2d(48, 48, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.ConvTranspose2d(48, 48, 3, stride=2, padding=1, output_padding=1))\n",
        " self._block4_dn = nn.Sequential(\n",
        " nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.ConvTranspose2d(96, 96, 3, stride=2, padding=1, output_padding=1))\n",
        " self._block5_dn = nn.Sequential(\n",
        " nn.Conv2d(144, 96, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.ConvTranspose2d(96, 96, 3, stride=2, padding=1, output_padding=1))\n",
        " self._block6_dn = nn.Sequential(\n",
        " nn.Conv2d(96 + in_channels, 64, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.Conv2d(64, 32, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.Conv2d(32, out_channels, 3, stride=1, padding=1),\n",
        " nn.LeakyReLU(0.1))\n",
        " self._block1_wm = nn.Sequential(\n",
        " nn.Conv2d(in_channels, 48, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.Conv2d(48, 48, 3, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.MaxPool2d(2))\n",
        " self._block2_wm = nn.Sequential(\n",
        " nn.Conv2d(48, 48, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.MaxPool2d(2))\n",
        " self._block3_wm = nn.Sequential(\n",
        " nn.Conv2d(48, 48, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.ConvTranspose2d(48, 48, 3, stride=2, padding=1, output_padding=1))\n",
        " self._block4_wm = nn.Sequential(\n",
        " nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.ConvTranspose2d(96, 96, 3, stride=2, padding=1, output_padding=1))\n",
        " self._block5_wm = nn.Sequential(\n",
        " nn.Conv2d(144, 96, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.ConvTranspose2d(96, 96, 3, stride=2, padding=1, output_padding=1))\n",
        " self._block6_wm = nn.Sequential(\n",
        " nn.Conv2d(96 + in_channels, 64, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.Conv2d(64, 32, 3, stride=1, padding=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.Conv2d(32, out_channels, 3, stride=1, padding=1),\n",
        " nn.LeakyReLU(0.1))\n",
        "\n",
        " self.avg_dn = nn.AdaptiveAvgPool2d((1, 1))\n",
        " self.attn_dn = nn.Sequential(\n",
        " nn.Conv2d(144, 6, kernel_size=1, stride=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.Conv2d(6, 144, kernel_size=1, stride=1),\n",
        " nn.Sigmoid())\n",
        " self.avg_wm = nn.AdaptiveAvgPool2d((1, 1))\n",
        " self.attn_wm = nn.Sequential(\n",
        " nn.Conv2d(144, 6, kernel_size=1, stride=1),\n",
        " nn.ReLU(inplace=True),\n",
        " nn.Conv2d(6, 144, kernel_size=1, stride=1),\n",
        " nn.Sigmoid())\n",
        " self.out = nn.Sequential(\n",
        " nn.Conv2d(out_channels * 2, out_channels, kernel_size=3, stride=1, padding=1),\n",
        " nn.LeakyReLU(0.1))\n",
        "\n",
        " self._init_weights()\n",
        "\n",
        " def _init_weights(self):\n",
        " for m in self.modules():\n",
        " if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        " nn.init.kaiming_normal_(m.weight.data)\n",
        " m.bias.data.zero_()\n",
        "\n",
        " def forward(self, x):\n",
        " pool1_dn = self._block1_dn(x)\n",
        " pool2_dn = self._block2_dn(pool1_dn)\n",
        " pool3_dn = self._block2_dn(pool2_dn)\n",
        " pool4_dn = self._block2_dn(pool3_dn)\n",
        " pool5_dn = self._block2_dn(pool4_dn)\n",
        " upsample5_dn = self._block3_dn(pool5_dn)\n",
        " concat5_dn = torch.cat((upsample5_dn, pool4_dn), dim=1)\n",
        " upsample4_dn = self._block4_dn(concat5_dn)\n",
        " concat4_dn = torch.cat((upsample4_dn, pool3_dn), dim=1)\n",
        " upsample3_dn = self._block5_dn(concat4_dn)\n",
        " concat3_dn = torch.cat((upsample3_dn, pool2_dn), dim=1)\n",
        " upsample2_dn = self._block5_dn(concat3_dn)\n",
        " concat2_dn = torch.cat((upsample2_dn, pool1_dn), dim=1)\n",
        " upsample1_dn = self._block5_dn(concat2_dn)\n",
        " concat1_dn = torch.cat((upsample1_dn, x), dim=1)\n",
        " out_denoise = self._block6_dn(concat1_dn)\n",
        "\n",
        " pool1_wm = self._block1_wm(out_denoise)\n",
        " pool2_wm = self._block2_wm(pool1_wm)\n",
        " pool3_wm = self._block2_wm(pool2_wm)\n",
        " pool4_wm = self._block2_wm(pool3_wm)\n",
        " pool5_wm = self._block2_wm(pool4_wm)\n",
        " upsample5_wm = self._block3_wm(pool5_wm)\n",
        " concat5_wm = torch.cat((upsample5_wm, pool4_wm), dim=1)\n",
        " upsample4_wm = self._block4_wm(concat5_wm)\n",
        " concat4_wm = torch.cat((upsample4_wm, pool3_wm), dim=1)\n",
        " upsample3_wm = self._block5_wm(concat4_wm)\n",
        " concat3_wm = torch.cat((upsample3_wm, pool2_wm), dim=1)\n",
        " upsample2_wm = self._block5_wm(concat3_wm)\n",
        " concat2_wm = torch.cat((upsample2_wm, pool1_wmphysics/chemistry practicals for class 11 & 12 VGS for CSE, NEET, JEE, CBSE, ICSE, Karnataka (PUC), National, International, IGCSE & IB Boards - Free Study Material, Solved Sample Question Papers & Practice Questions, Online Study Resources for Class 1 to 12 | VGS Vidyashram School - VGS Global School pool1_dw = self._block1_dw(x)\n",
        " pool2_dw = self._block2_dw(pool1_dw)\n",
        " pool3_dw = self._block2_dw(pool2_dw)\n",
        " pool4_dw = self._block2_dw(pool3_dw)\n",
        " pool5_dw = self._block2_dw(pool4_dw)\n",
        " upsample5_dw = self._block3_dw(pool5_dw)\n",
        " concat5_dw = torch.cat((upsample5_dw, pool4_dw), dim=1)\n",
        " upsample4_dw = self._block4_dw(concat5_dw)\n",
        " concat4_dw = torch.cat((upsample4_dw, pool3_dw), dim=1)\n",
        " upsample3_dw = self._block5_dw(concat4_dw)\n",
        " concat3_dw = torch.cat((upsample3_dw, pool2_dw), dim=1)\n",
        " upsample2_dw = self._block5_dw(concat3_dw)\n",
        " concat2_dw = torch.cat((upsample2_dw, pool1_dw), dim=1)\n",
        " mid_dn = self.avg_dn(concat2_dn)\n",
        " Scale_dn = self.attn_dn(mid_dn)\n",
        " concat2_dw = concat2_dw * Scale_dn\n",
        " upsample1_dw = self._block5_dw(concat2_dw)\n",
        " concat1_dw = torch.cat((upsample1_dw, x), dim=1)\n",
        " main_out_mid = self._block6_dw(concat1_dw)\n",
        "\n",
        " pool1_dw2 = self._block1_dw2(main_out_mid)\n",
        " pool2_dw2 = self._block2_dw2(pool1_dw2)\n",
        " pool3_dw2 = self._block2_dw2(pool2_dw2)\n",
        " pool4_dw2 = self._block2_dw(pool3_dw2)\n",
        " pool5_dw2 = self._block2_dw(pool4_dw2)\n",
        " upsample5_dw2 = self._block3_dw(pool5_dw2)\n",
        " concat5_dw2 = torch.cat((upsample5_dw2, pool4_dw2), dim=1)\n",
        " upsample4_dw2 = self._block4_dw(concat5_dw2)\n",
        " concat4_dw2 = torch.cat((upsample4_dw2, pool3_dw2), dim=1)\n",
        " upsample3_dw2 = self._block5_dw(concat4_dw2)\n",
        " concat3_dw2 = torch.cat((upsample3_dw2, pool2_dw2), dim=1)\n",
        " upsample2_dw2 = self._block5_dw(concat3_dw2)\n",
        " concat2_dw2 = torch.cat((ups  Free Study Material, Solved Sample Question Papers & Practice Questions for Class 1 to 12 | VGS Vidyashram School - VGS Global School | Online Study Resources | Free Study Material, Solved Sample Question Papers & Practice Questions for Class 1 to 12 | VGS Vidyashram School - VGS Global School | Online Study Resources | Free Study Material, Solved Sample Question Papers & Practice Questions for Class 1 to 12 | VGS Vidyashram School - VGS Global School | Online Study Resources | Free Study Material, Solved Sample Question Papers & Practice Questions for Class 1 to 12 | VGS Vidyashram School - VGS Global School | Online Study Resources | Free Study Material, Solved Sample Question Papers & Practice Questions for Class 1 to 12 | VGS Vidyashram School - VGS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5R95SpPAqjG",
        "outputId": "a4dcf1ff-ab0a-4ca7-bb89-d3ea42343572"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (3.13.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.6.0+cu124)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    }
  ]
}